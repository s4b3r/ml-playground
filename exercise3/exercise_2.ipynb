{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOPP 2018W Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, please set the variables above to your student ID and name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentID = '00000000'\n",
    "name = 'Your Name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the template for the second exercise in data oriented programming paradigms (2018W). \n",
    "Before you get started, please read the instructions in this notebook carefully.\n",
    "\n",
    "### Preliminaries:\n",
    " - In order to get a valid score, you must rename this file from `exercise_2.ipynb` to `%s_exercise_2.ipynb % student_id`.\n",
    "\n",
    "- Please use only Python version 3 (3.6+ recommended). It is recommended to install Anaconda or Miniconda. \n",
    "\n",
    "- Most of the code in this notebook will be scored using unit tests. \n",
    "- Please use the code stubs provided, do not rename any functions, and add and modify your code only at the provided markers. \n",
    "- Check and make sure that your submission executes without any errors before submitting it\n",
    "- The submission will be executed on a Unix system (if you use Windows, please make sure that you use the functionality provided in the os module to make sure your path names work on Unix)\n",
    "- For the submission, only this (renamed) notebook file needs to be uploaded to TUWEL. The data will be available on the same path in the directory we put your notebook for grading.\n",
    "\n",
    "\n",
    "The submission deadline is **12.12.2018 23:55.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The only imports allowed are those contained in Python's standard library, pandas, numpy, scipy and matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import sklearn..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "In this exercise, you will \n",
    " * use `pandas` to read, prepare and transform data,\n",
    " * use `matplotlib` to visually alayse data,\n",
    " * use `scikit-learn` to build prediction models.\n",
    "\n",
    "\n",
    "The goal of this exercise is to model the relationship between weather observations and the prevalence of new influenza infections.\n",
    "\n",
    "To investigate a potential relationship, we will use two datasets:\n",
    " * daily weather observation data in Vienna (2012-2018)\n",
    " * weekly reports on [new influenza infections](https://www.data.gv.at/katalog/dataset/grippemeldedienst-stadt-wien) in Vienna (2009-2018).\n",
    "\n",
    "Note that the weather data set differs from the one used in exercise 1 and be sure to use the one provided for exercise 2. The data to be used can be found in the subdirectory named `data`. \n",
    "If you develop your submission on Windows, please make sure that you don't use any backslashes in the file names, because the submission won't run on Unix systems. \n",
    "Either use normal slashes, or use the functions provided in the `os.path` module. \n",
    "If you stick with the provided function templates, you should be fine.\n",
    "\n",
    "To complete this exercise, you will have to:\n",
    "* prepare the data, which (at a minimum) involves the following:\n",
    "    - handling missing values,\n",
    "    - handling outliers\n",
    "    - temporal alignment (i.e. convert daily data to weekly data using appropriate aggregation functions),\n",
    "* analyse the data:\n",
    "    - compare descriptive statistics,\n",
    "    - visually investigate the raw data to gain an understanding of the data, identify patterns, outliers etc.,\n",
    "    - look at the relationship between the variables of interest,\n",
    "* model the relationship:\n",
    "    - fit a model that predicts new infections from weather observation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Load Data\n",
    "\n",
    "### Weather observations <span style=\"color:blue\">(1 P)</span>\n",
    "\n",
    "As a first step, implement the method `load_weather_data()`, which should read all individual (yearly) data sets from the csv files in `data` into a single `pd.DataFrame` and return it. \n",
    "\n",
    "- add a column for the year\n",
    "- add a `week` column containing the week number (use Pandas built-in datetime handling features to get the week number for each given date)\n",
    "- create a `MultiIndex` from the date columns with the following hierarchy: `year` - `month` - `week` - `day` (make sure to label them accordingly)\n",
    "- make sure that all columns are appropriately typed\n",
    "- make sure that you load all the data (2012-2018)\n",
    "\n",
    "**Hints:**\n",
    " - It is advisable not to append each data set individually, but to read each data frame, store it into a list and  combine them once at the end.\n",
    " - Your resulting data frame should look as follows:\n",
    " \n",
    "![Weather data frame example](weather_dataFrame_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weather_data():\n",
    "    \"\"\" \n",
    "    Load all weather data files and combine them into a single Pandas DataFrame.\n",
    "    Add a week column and a hierarchical index (year, month, week, day)\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    weather_data: data frame containing the weather data\n",
    "    \"\"\"\n",
    "    # TODO: your changes here\n",
    "    weather_data = pd.DataFrame()\n",
    "    return weather_data\n",
    "\n",
    "data_weather = load_weather_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influenza infections <span style=\"color:blue\">(1 P)</span>\n",
    "\n",
    "Load and prepare the second data set, which contains the number of new influenza infections on a weekly basis, as follows:\n",
    "\n",
    "- get rid of all columns except `Neuerkrankungen pro Woche`, `Jahr`, and `Kalenderwoche`\n",
    "- rename `Neuerkrankungen pro Woche` to `weekly_infections`\n",
    "- create a `MultiIndex` from the `Jahr` (→ `year`) and `Kalenderwoche` (→ `week`) columns\n",
    "- make sure that all columns are appropriately typed\n",
    "- your resulting data frame should look as follows:\n",
    "\n",
    "\n",
    "![Example data frame](influenza_dataFrame_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_influenza_data():\n",
    "    \"\"\" \n",
    "    Load and prepare the influenza data file\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    influenza_data: data frame containing the influenza data\n",
    "    \"\"\"\n",
    "    # TODO: your changes here\n",
    "    influenza_data = pd.DataFrame()\n",
    "    \n",
    "    return influenza_data\n",
    "\n",
    "data_influenza = load_influenza_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Handling Missing values <span style=\"color:blue\">(4 P)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you take a closer look at the data, you will notice that a few of the observations are missing.\n",
    "\n",
    "There are a wide range of standard strategies to deal with such missing values, including:\n",
    "\n",
    "- row deletion\n",
    "- substitution methods (e.g., replace with mean or median)\n",
    "- hot-/cold-deck methods (impute from a randomly selected similar record)\n",
    "- regression methods\n",
    "\n",
    "To decide which strategy is appropriate, it is important to investigate the mechanism that led to the missing values to find out whether the missing data is missing completely at random (MCAR), missing at random (MAR), or missing not at random (MNAR). \n",
    "\n",
    " - **MCAR** means that there is no relationship between the missingness of the data and any of the values.\n",
    " - **MAR** means that that there is a systematic relationship between the propensity of missing values and the observed data, but not the missing data.\n",
    " - **MNAR** means that there is a systematic relationship between the propensity of a value to be missing and its values. \n",
    "\n",
    "To find out more about what mechanisms may have caused the missing values, you talked to the metereologist that compiled the data. \n",
    "She told you that she does not know why some of the temperature readings are missing, but that it may be that someone forgot to record them. In any case, it is likely that the propensity of a temperature value to be missing does not have anything to do with the weather itself.\n",
    "\n",
    "As far as the missing humidity readings are concerned, she says that according to her experience, she suspects that the humidity sensor is less reliable in hot weather.\n",
    "\n",
    "The missing wind speed and direction sensor readings were due to a hardware defect.\n",
    "\n",
    "Check the plausibility of these hypotheses in the data, consider the implications, and devise an appropriate strategy to deal with the various missing values.\n",
    "\n",
    "To implement your strategy, you can use a range of standard mechanisms provided by Pandas or implement a custom strategy (for extra points):\n",
    "\n",
    "**Chocolate challenge:**\n",
    "More advanced strategies (e.g., building a machine learning model that predicts MAR data based on other observed values) may give you better results if the propensity of data to be missing is of a systematic nature. If you want to participate in the chocolate challenge for the best approximation of missing values, you can implement your missing value prediction model in `handleMissingValuesAdvanced` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missingValues_simple(incomplete_data):\n",
    "    \"\"\" \n",
    "    Parameters\n",
    "    --------\n",
    "    incomplete_data: data frame containing missing values \n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    complete_data: data frame not containing any missing values\n",
    "    \"\"\"\n",
    "    # TODO: your changes here\n",
    "    complete_data = incomplete_data.fillna(0)\n",
    "    \n",
    "    return complete_data\n",
    "\n",
    "\n",
    "def handle_missingValues_advanced (incomplete_data):\n",
    "    \"\"\" \n",
    "    Parameters\n",
    "    --------\n",
    "    data: data frame containing missing values \n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    data: data frame not containing any missing values\n",
    "    \"\"\"\n",
    "    # TODO: your changes here\n",
    "    \n",
    "    return complete_data\n",
    "    \n",
    "data_weather_complete = handle_missingValues_simple(data_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Discussion\n",
    "\n",
    "#### Pros and Cons of strategies for dealing with missing data <span style=\"color:blue\">(1 P)</span>\n",
    "\n",
    "In the cell provided below, discuss the PROs and CONs of various strategies (row deletion, imputation, hot deck methods etc.) for dealing with missing data. Discuss when it is appropriate to use each method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[T2_Pros_and_Cons]\n",
    "\n",
    "<span style=\"color:blue\">**TODO:**</span> Please remove this text, but keep the marker above and answer here...\n",
    "\n",
    "[/T2_Pros_and_Cons]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your chosen strategy <span style=\"color:blue\">(1 P)</span>\n",
    "\n",
    "Explain your chosen strategy for dealing with missing values for the various attributes in the cell below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[T2_MissingValueStrategy]\n",
    "\n",
    "<span style=\"color:blue\">**TODO:**</span> Please remove this text, but keep the marker above and answer here...\n",
    "\n",
    "[/T2_MissingValueStrategy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Handling Outliers <span style=\"color:blue\">(2 P)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you take a closer look at some of the observations, you should notice that some of the temperature values are not particularly plausible (hint: plotting histograms of the distributions helps). Hypothesize on the nature of these outliers and implement a strategy to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(noisy_data):\n",
    "    \"\"\" \n",
    "    Parameters\n",
    "    --------\n",
    "    noisy_data: data frame that contains outliers\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    cleaned_data: data frame with outliers\n",
    "    \"\"\"\n",
    "    # TODO: your changes here\n",
    "    cleaned_data = noisy_data\n",
    "    return cleaned_data\n",
    "    \n",
    "data_weather_cleaned = handle_outliers(data_weather_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your chosen strategy <span style=\"color:blue\">(1 P)</span>\n",
    "\n",
    "Explain your chosen strategy for dealing with outliers in the cell below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[T3_OutlierStrategy]\n",
    "\n",
    "<span style=\"color:blue\">**TODO:**</span> Please remove this text, but keep the marker above and answer here...\n",
    "\n",
    "[/T3_OutlierStrategy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Aggregate values <span style=\"color:blue\">(1 P)</span>\n",
    "\n",
    "Aggregate the observations on a weekly basis. Return a data frame with a hierarchical index (levels `year` and `week`) on the vertical axis and the following weekly aggregations as columns:\n",
    "\n",
    "- `temp_weeklyMin`: minimum of `temp_dailyMin`\n",
    "- `temp_weeklyMax`: mean of `temp_dailyMax`\n",
    "- `temp_weeklyMean`: mean of `temp_dailyMean`\n",
    "- `temp_7h_weeklyMedian`: median of `temp_7h`\n",
    "- `temp_14h_weeklyMedian`: median of `temp_14h`\n",
    "- `temp_19h_weeklyMedian`: median of `temp_19h`\n",
    "\n",
    "- `hum_weeklyMean`: mean of `hum_dailyMean`\n",
    "- `hum_7h_weeklyMedian`: median of `hum_7h`\n",
    "- `hum_14h_weeklyMedian`: median of `hum_14h`\n",
    "- `hum_19h_weeklyMedian`: median of `hum_19h`\n",
    "\n",
    "- `precip_weeklyMean`: mean of `precip`\n",
    "- `wind_mSec_mean`: mean of `wind_mSec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_weekly(data):\n",
    "    \"\"\" \n",
    "    Parameters\n",
    "    --------\n",
    "    data: weather data frame\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    weekly_stats: data frame that contains statistics aggregated on a weekly basis\n",
    "    \"\"\"\n",
    "    # TODO: your changes here\n",
    "    weekly_weather_data = pd.DataFrame()    \n",
    "\n",
    "    \n",
    "    return weekly_weather_data\n",
    "\n",
    "data_weather_weekly = aggregate_weekly(data_weather_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Merge influenza and weather datasets <span style=\"color:blue\">(1 P)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the `data_weather_weekly` and `data_influenza` datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_data(weather_df, influenza_df):\n",
    "    \"\"\" \n",
    "    Parameters\n",
    "    --------\n",
    "    weather_df: weekly weather data frame\n",
    "    influenza_df: influenza data frame\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    merged_data: merged data frame that contains both weekly weather observations and prevalence of influence infections\n",
    "    \"\"\"\n",
    "    # TODO: your changes here\n",
    "    merged_data = pd.DataFrame()    \n",
    "\n",
    "    return merged_data\n",
    "\n",
    "data_merged = merge_data(data_weather_weekly, data_influenza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Visualization <span style=\"color:blue\">(4 P)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better understanding of the dataset, create visualizations of the merged data set that help to explore the potential relationships between the variables before starting to develop a model.\n",
    "\n",
    "\n",
    "**Note:** To hand in multiple figures, change the code accordingly (additional files should be named `%s_%u.png\" % student_id, fileCount`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0dc8c60d1993>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: your changes here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: your changes here\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([1,1,1,1])\n",
    "plt.plot([1,2])\n",
    "\n",
    "\n",
    "fig.savefig(studentID+'_01.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Influenza prediction model <span style=\"color:blue\">(11 P)</span>\n",
    "\n",
    "Build a model to predict the number of influenza incidents for the year 2018 (discarding all the data available for 2018) based on data of previous year using `sklearn`. \n",
    "\n",
    " - Choose appropriate machine learning algorithm(s) for the problem at hand\n",
    " - Make sure your results are reproducible\n",
    " - Don't hesitate to go back to previous steps if you notice any data quality issues\n",
    " - If your chosen algorithm has specific parameters, explore their effect with different settings using 10-fold cross-validation\n",
    " - Experiment with different training/test splits\n",
    " - If appropriate, try different scaling approaches (min/max, z-score,..).\n",
    " - How good does your model fit when you evaluate it with the test data set?\n",
    " - How good are your predictions when you use the actual data available for 2018 as a validation set?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: your model implementation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach and algorithm <span style=\"color:blue\">(2 P)</span>\n",
    "Motivate your approach and choice of algorithm here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[T7_Model_Description]\n",
    "\n",
    "<span style=\"color:blue\">**TODO:**</span> Please remove this text with your answer here, but keep the marker above.\n",
    "\n",
    "[/T7_Model_Description]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings  <span style=\"color:blue\">(2 P)</span>\n",
    "Summarize your findings and lessens learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[T7_Model_Findings]\n",
    "\n",
    "<span style=\"color:blue\">**TODO:**</span> Please remove this text with your answer here, but keep the marker above.\n",
    "\n",
    "[/T7_Model_Findings]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
